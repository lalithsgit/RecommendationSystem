{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis - Breaking Hits\n",
    "## Authors: Wing Yan Sang and Iman Singh\n",
    "## Date: 12/12/2017\n",
    "\n",
    "<p><a name=\"sections\"></a></p>\n",
    "\n",
    "\n",
    "## Sections\n",
    "- <a href=\"#pre-processing\"> Pre-Processing</a><br>\n",
    "- <a href=\"#graphs\"> Network Graphs</a><br>\n",
    "- <a href=\"#centrality\"> Centrality</a><br>\n",
    " - <a href=\"#centrality1\">Centrality Analysis 1: \"Celebrities\"</a><br>\n",
    " - <a href=\"#centrality2\">Centrality Analysis 2: \"Gossipmongers\"</a><br>\n",
    " - <a href=\"#centrality3\">Centrality Analysis 3: \"Boundary Spanners\"</a><br>\n",
    " - <a href=\"#centrality4\">Centrality Analysis 4: \"Gray Cardinals\"</a><br>\n",
    " - <a href=\"#centrality5\">Centrality Analysis 5: \"Page Rank\"</a><br>   \n",
    " - <a href=\"#centrality_summary\">Centrality Analysis: Summary </a><br>   \n",
    "- <a href=\"#ccc\"> Cliques, Clusters, Components</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import mysql.connector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector as sql\n",
    "import breakinghits_script as bh\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"pre-processing\"></a></p>\n",
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function pulls specified data from Breaking Hits MySQL server\n",
    "# parameters: 'table_name' as string, 'col_names' as list of strings\n",
    "\n",
    "def get_table(table_name, col_names):    \n",
    "    cnx = sql.connect(user='breaking_read',\n",
    "                                  password='(hHy;gTPMnet',\n",
    "                                  host='206.225.82.147',\n",
    "                                  database='breaking_livedb')\n",
    "    cur = cnx.cursor()\n",
    "    select_statement = 'SELECT ' + ', '.join(col_names) + ' FROM ' + table_name +';'\n",
    "    cur.execute(select_statement)\n",
    "    rows = cur.fetchall()                         # get all selected rows\n",
    "    field_names = [i[0] for i in cur.description] # get all column names\n",
    "    cnx.close() # close the sql connection\n",
    "\n",
    "    table = pd.DataFrame(rows, columns=field_names)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#removes rows with missing data \n",
    "\n",
    "def dropMissing(df):\n",
    "    df = df.replace('', np.nan, regex=True) #convert empty cells to nan\n",
    "    df = df.dropna()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converts object to int64 for first two cols in data frame. (assumes no missing values)\n",
    "\n",
    "def convertInt(df):\n",
    "    for col in df.columns[:1]:\n",
    "        if (df[col].dtype == 'object'):\n",
    "            df[col] = df[col].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters string specifying connection type: follow, message, view, sociallink, rating, save, spotlight, comment\n",
    "# Returns formatted pandas dataframe\n",
    "\n",
    "def get_dataframe(connection='follow'):  \n",
    "    if (connection == 'follow'):\n",
    "        df = get_table('user_following', ['followed_id', 'follower_id', 'date_followed'])\n",
    "    elif (connection == 'sociallink'):\n",
    "        df = get_table('bh_social_link_activity', ['user_id_shared', 'user', 'date_shared'])\n",
    "    elif (connection == 'message'):\n",
    "        df = get_table('bh_messenger', ['sendfrom', 'sendto', 'u_read', 'data_added'])\n",
    "    elif (connection == 'view'):\n",
    "        df = get_table('bh_music_views', ['artists_id', 'user_id', 'date_added'])\n",
    "    elif (connection == 'rating'):\n",
    "        df = get_table('user_music_votes', ['user_id', 'user_music_id', 'rating', 'date_added'])\n",
    "    elif (connection == 'save'):\n",
    "        df = get_table('user_saved', ['music_id', 'user_id', 'date_saved'])   \n",
    "    elif (connection == 'spotlight'):\n",
    "        df = get_table('user_spotlight', ['music_id', 'user_id', 'date_added'])   \n",
    "    elif (connection == 'comment'):\n",
    "        df = get_table('user_music_comments', ['user_music_id', 'user_id', 'date_added'])\n",
    "    else:\n",
    "        return\n",
    "   \n",
    "    #Drop missing rows and convert and convert object to int for each column:   \n",
    "    df = dropMissing(df)\n",
    "    df = convertInt(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Draw edges between nodes of a graph or directed graph\n",
    "#Parameters: graph object (directed or undirected), dataframe that contains network info\n",
    "#Returns: graph object with edges drawn\n",
    "\n",
    "def add_edges(G, df):\n",
    "    for row in df.itertuples():\n",
    "        if ('u_read' in list(df)):\n",
    "            G.add_edge(row[1], row[2], read=row[3], date=row[4])\n",
    "        elif ('rating' in list(df)):\n",
    "            G.add_edge(row[1], row[2], rating=row[3], date=row[4])\n",
    "        else:\n",
    "            G.add_edge(row[2], row[1], date=row[3])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Define function to filter graph object to only include those that are tagged as critic/artist and label\n",
    "#nodes as critic/artist\n",
    "def get_artcric_list(G):\n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(G.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(G.nodes())] #list of artists\n",
    "    s1 = l_list + a_list #combined list of critics and artists \n",
    "    s2 = list(set(s1) & set(G.nodes())) #list of people in G.nodes() and tagged as artist or critic\n",
    "    \n",
    "    return s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#define node attribute 'user_type' = artist or critic\n",
    "def add_artcric_keys(G):\n",
    "    key_list = G.nodes()\n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(G.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(G.nodes())] #list of artists\n",
    "    \n",
    "    for i in range(0,len(key_list)): \n",
    "        if (key_list[i] in l_list):\n",
    "            G.node[key_list[i]]['user_type'] = 'critic'\n",
    "        else:\n",
    "            G.node[key_list[i]]['user_type'] = 'artist'\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define node attribute 'user_type' = artist or critic\n",
    "def filter_graph_artcric(G):\n",
    "    key_list = G.nodes()\n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(G.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(G.nodes())] #list of artists\n",
    "    s1 = l_list + a_list #combined list of critics and artists \n",
    "    s2 = list(set(s1) & set(G.nodes())) #list of people in G.nodes() and tagged as artist or critic\n",
    "    \n",
    "    G_reduced = nx.Graph(G.subgraph(s2))\n",
    "    \n",
    "    for i in range(0,len(key_list)): \n",
    "        if (key_list[i] in l_list):\n",
    "            G_reduced.node[key_list[i]]['user_type'] = 'critic'\n",
    "        else:\n",
    "            G_reduced.node[key_list[i]]['user_type'] = 'artist'\n",
    "    return G_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define node attribute 'user_type' = artist or critic\n",
    "def filter_digraph_artcric(DG):\n",
    "    key_list = DG.nodes()\n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(DG.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(DG.nodes())] #list of artists\n",
    "    s1 = l_list + a_list #combined list of critics and artists \n",
    "    s2 = list(set(s1) & set(DG.nodes())) #list of people in G.nodes() and tagged as artist or critic\n",
    "    \n",
    "    DG_reduced = nx.DiGraph(DG.subgraph(s2))\n",
    "    \n",
    "    for i in range(0,len(key_list)): \n",
    "        if (key_list[i] in l_list):\n",
    "            DG_reduced.node[key_list[i]]['user_type'] = 'critic'\n",
    "        else:\n",
    "            DG_reduced.node[key_list[i]]['user_type'] = 'artist'\n",
    "    return DG_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Define function to filter graph object to only include those that are tagged as critic/artist and label\n",
    "#nodes as critic/artist. No direction to the edges.\n",
    "def filter_graph(G):\n",
    "    G_reduced = nx.Graph(G.subgraph(get_artcric_list(G)))\n",
    "    G_reduced = add_artcric_keys(G_reduced)\n",
    "    return G_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_userlists(df):\n",
    "    userlist = sorted(set(df['user_id'].tolist()))\n",
    "    return userlist\n",
    "\n",
    "def get_musiclists_1(df):\n",
    "    musiclist = sorted(set(df['user_music_id'].tolist()))\n",
    "    return musiclist\n",
    "\n",
    "def get_musiclists_2(df):\n",
    "    musiclist = sorted(set(df['music_id'].tolist()))\n",
    "    return musiclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameter: dataframe that user wants to use for creating bipartite graph\n",
    "#mutates dataframe into one that has negated value for music_id\n",
    "\n",
    "def negate_musicid_1(df):\n",
    "    df['user_music_id'] = -1 * df_rating['user_music_id']   \n",
    "\n",
    "def negate_musicid_2(df):\n",
    "    df['music_id'] = -1 * df['music_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameter: dataframe to create bipartite graph\n",
    "#Returns: bipartite graph\n",
    "\n",
    "def get_bigraph_1(df):\n",
    "    BG = nx.Graph()\n",
    "    BG.add_nodes_from(df['user_id'], bipartite = 0)\n",
    "    BG.add_nodes_from(df['user_music_id'], bipartite=1)\n",
    "    zipped_edges = zip(df['user_id'], df['user_music_id'])\n",
    "    BG.add_edges_from(zipped_edges)\n",
    "    return BG\n",
    "\n",
    "def get_bigraph_2(df):\n",
    "    BG = nx.Graph()\n",
    "    BG.add_nodes_from(df['user_id'], bipartite = 0)\n",
    "    BG.add_nodes_from(df['music_id'], bipartite=1)\n",
    "    zipped_edges = zip(df['user_id'], df['music_id'])\n",
    "    BG.add_edges_from(zipped_edges)\n",
    "    return BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameter: bipartite graph opbject\n",
    "#Output: 2 lists: top_nodes and bottom_nodes\n",
    "\n",
    "def get_bipartite_nodes(BG):\n",
    "    top_nodes, bottom_nodes = bipartite.sets(B)\n",
    "    \n",
    "    top_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==0}\n",
    "    bottom_nodes = set(B) - top_nodes\n",
    "    \n",
    "    return top_nodes, bottom_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameter: dataframe used for bipartite graph\n",
    "#Output: 'pos' argument for use for graph axes\n",
    "\n",
    "def get_pos_1(df):\n",
    "    pos = {node:[0, i] for i,node in enumerate(df['user_id'])}\n",
    "    pos.update({node:[1, i] for i,node in enumerate(df['user_music_id'])})\n",
    "    return pos\n",
    "\n",
    "def get_pos_2(df):\n",
    "    pos = {node:[0, i] for i,node in enumerate(df['user_id'])}\n",
    "    pos.update({node:[1, i] for i,node in enumerate(df['music_id'])})\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Count  Percentage\n",
      "followed_id        0         0.0\n",
      "follower_id        0         0.0\n",
      "date_followed      0         0.0 \n",
      "\n",
      "            Count  Percentage\n",
      "sendfrom        0         0.0\n",
      "sendto          0         0.0\n",
      "u_read          0         0.0\n",
      "data_added      0         0.0 \n",
      "\n",
      "            Count  Percentage\n",
      "artists_id      0         0.0\n",
      "user_id         0         0.0\n",
      "date_added      0         0.0 \n",
      "\n",
      "                Count  Percentage\n",
      "user_id_shared      0         0.0\n",
      "user                0         0.0\n",
      "date_shared         0         0.0 \n",
      "\n",
      "               Count  Percentage\n",
      "user_id            0         0.0\n",
      "user_music_id      0         0.0\n",
      "rating             0         0.0\n",
      "date_added         0         0.0 \n",
      "\n",
      "            Count  Percentage\n",
      "music_id        0         0.0\n",
      "user_id         0         0.0\n",
      "date_saved      0         0.0 \n",
      "\n",
      "            Count  Percentage\n",
      "music_id        0         0.0\n",
      "user_id         0         0.0\n",
      "date_added      0         0.0 \n",
      "\n",
      "               Count  Percentage\n",
      "user_music_id      0         0.0\n",
      "user_id            0         0.0\n",
      "date_added         0         0.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine missingness of the various dataframes:\n",
    "connection = ['follow', 'message', 'view', 'sociallink', 'rating', 'save', 'spotlight', 'comment']\n",
    "[print(bh.countMissing(get_dataframe(i)),'\\n') for i in connection]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "follow  dataframe \n",
      "\n",
      "followed_id               int64\n",
      "follower_id               int64\n",
      "date_followed    datetime64[ns]\n",
      "dtype: object\n",
      "message  dataframe \n",
      "\n",
      "followed_id               int64\n",
      "follower_id               int64\n",
      "date_followed    datetime64[ns]\n",
      "dtype: object\n",
      "view  dataframe \n",
      "\n",
      "followed_id               int64\n",
      "follower_id               int64\n",
      "date_followed    datetime64[ns]\n",
      "dtype: object\n",
      "sociallink  dataframe \n",
      "\n",
      "followed_id               int64\n",
      "follower_id               int64\n",
      "date_followed    datetime64[ns]\n",
      "dtype: object\n",
      "rating  dataframe \n",
      "\n",
      "followed_id               int64\n",
      "follower_id               int64\n",
      "date_followed    datetime64[ns]\n",
      "dtype: object\n",
      "save  dataframe \n",
      "\n",
      "followed_id               int64\n",
      "follower_id               int64\n",
      "date_followed    datetime64[ns]\n",
      "dtype: object\n",
      "spotlight  dataframe \n",
      "\n",
      "followed_id               int64\n",
      "follower_id               int64\n",
      "date_followed    datetime64[ns]\n",
      "dtype: object\n",
      "comment  dataframe \n",
      "\n",
      "followed_id               int64\n",
      "follower_id               int64\n",
      "date_followed    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#examine column types for each data frame\n",
    "\n",
    "connection = ['follow', 'message', 'view', 'sociallink', 'rating', 'save', 'spotlight', 'comment']\n",
    "\n",
    "for i in connection:\n",
    "    print(i, \" dataframe\", '\\n')\n",
    "    print(get_dataframe().dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"graphs\"></a></p>\n",
    "## Network Graphs\n",
    "\n",
    "-- View Follow/Followed network \n",
    "\n",
    "-- Define function to filter graph to only include users tagged critics/artists and to add attribute artist/critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#call function to get graph and dataframes for all four connection types\n",
    "df_follow = get_dataframe('follow')\n",
    "df_message = get_dataframe('message')\n",
    "df_view = get_dataframe('view')\n",
    "df_sociallink = get_dataframe('sociallink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_follow = add_edges(nx.Graph(), df_follow)\n",
    "DG_follow = add_edges(nx.DiGraph(), df_follow)\n",
    "G_message = add_edges(nx.Graph(), df_message)\n",
    "DG_message = add_edges(nx.DiGraph(), df_message)\n",
    "G_view = add_edges(nx.Graph(), df_view)\n",
    "DG_view = add_edges(nx.DiGraph(), df_view)\n",
    "G_sociallink = add_edges(nx.Graph(), df_sociallink)\n",
    "DG_sociallink = add_edges(nx.DiGraph(), df_sociallink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "373",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-07c9b4b6ef41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG_follow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_graph_artcric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_follow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDG_follow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_digraph_artcric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDG_follow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mG_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_graph_artcric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDG_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_digraph_artcric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDG_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mG_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_graph_artcric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-28b08c4db842>\u001b[0m in \u001b[0;36mfilter_graph_artcric\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mG_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'critic'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mG_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'artist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mG_reduced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 373"
     ]
    }
   ],
   "source": [
    "G_follow = filter_graph_artcric(G_follow)\n",
    "DG_follow = filter_digraph_artcric(DG_follow)\n",
    "G_message = filter_graph_artcric(G_message)\n",
    "DG_message = filter_digraph_artcric(DG_message)\n",
    "G_view = filter_graph_artcric(G_view)\n",
    "DG_view = filter_digraph_artcric(DG_view)\n",
    "G_sociallink = filter_graph_artcric(G_sociallink)\n",
    "DG_sociallink = filter_digraph_artcric(DG_sociallink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot of network, whether tagged or not as listener/artist\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.title('Network Graph of Follower/Followed', fontsize = 20)\n",
    "nx.draw_networkx(GF, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot of network, whether tagged or not as listener/artist\n",
    "plt.figure(figsize=(20,15))\n",
    "nx.draw_networkx(DGF, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example using follow/followed connection\n",
    "G_reduced = nx.Graph(GF.subgraph(get_artcric_list(GF)))\n",
    "DG_reduced = nx.Graph(DGF.subgraph(get_artcric_list(DGF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(get_artcric_list(GF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function to filter graph object to only include those that are tagged as critic/artist and label\n",
    "#nodes as critic/artist. Edges marked with direction.\n",
    "def filter_digraph(DG):\n",
    "    DG_reduced = nx.DiGraph(DG.subgraph(get_artcric_list(DG)))    \n",
    "    DG_reduced = add_artcric_keys(DG)\n",
    "    return DG_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implement filter function and draw the filtered graph\n",
    "GF_reduced = filter_graph(GF)\n",
    "color_map = {}\n",
    "key_list = GF_reduced.nodes()\n",
    "\n",
    "for i in range(0, len(key_list)):\n",
    "    if(GF_reduced.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "\n",
    "colors = [color_map.get(node) for node in GF_reduced.nodes()]\n",
    "plt.figure(figsize=(20,20))\n",
    "nx.draw_networkx(GF_reduced, node_color = colors, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(GF_reduced.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DGF_reduced = filter_digraph(DGF)\n",
    "key_list = DGF_reduced.nodes()\n",
    "\n",
    "for i in range(0, len(key_list)):\n",
    "    if(DGF_reduced.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "        \n",
    "colors = [color_map.get(node) for node in DGF_reduced.nodes()]\n",
    "plt.figure(figsize=(20,20))\n",
    "nx.draw_networkx(DGF_reduced, node_color = colors, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#implement filter function and draw the filtered graph\n",
    "GM_reduced = filter_graph(GM)\n",
    "color_map = {}\n",
    "key_list = GM_reduced.nodes()\n",
    "\n",
    "for i in range(0, len(key_list)):\n",
    "    if(GM_reduced.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "\n",
    "colors = [color_map.get(node) for node in GM_reduced.nodes()]\n",
    "plt.figure(figsize=(20,15))\n",
    "nx.draw_networkx(GM_reduced, node_color = colors, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DGM_reduced = filter_digraph(DGM)\n",
    "color_map = {}\n",
    "key_list = DGM_reduced.nodes()\n",
    "for i in range(0, len(key_list)):\n",
    "    if(DGM_reduced.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "    \n",
    "colors = [color_map.get(node) for node in DGM_reduced.nodes()]\n",
    "plt.figure(figsize=(20,20))\n",
    "nx.draw_networkx(DGM_reduced, node_color = colors, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#implement filter function and draw the filtered graph\n",
    "GV_reduced = filter_graph(GV)\n",
    "color_map = {}\n",
    "key_list = GV_reduced.nodes()\n",
    "\n",
    "for i in range(0, len(key_list)):\n",
    "    if(GV_reduced.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "\n",
    "colors = [color_map.get(node) for node in GV_reduced.nodes()]\n",
    "plt.figure(figsize=(20,15))\n",
    "nx.draw_networkx(GV_reduced, node_color = colors, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DGV_reduced = filter_digraph(DGV)\n",
    "color_map = {}\n",
    "key_list = DGV_reduced.nodes()\n",
    "\n",
    "for i in range(0, len(key_list)):\n",
    "    if(DGV_reduced.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "        \n",
    "colors = [color_map.get(node) for node in DGV_reduced.nodes()]\n",
    "plt.figure(figsize=(20,20))\n",
    "nx.draw_networkx(DGV_reduced, node_color = colors, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#implement filter function and draw the filtered graph\n",
    "GS_reduced = filter_graph(GS)\n",
    "color_map = {}\n",
    "key_list = GS_reduced.nodes()\n",
    "\n",
    "for i in range(0, len(key_list)):\n",
    "    if(GS_reduced.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "\n",
    "colors = [color_map.get(node) for node in GS_reduced.nodes()]\n",
    "plt.figure(figsize=(20,15))\n",
    "nx.draw_networkx(GS_reduced, node_color = colors, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DGS_reduced = filter_digraph(DGS)\n",
    "key_list = DGS_reduced.nodes()\n",
    "color_map = {}\n",
    "\n",
    "for i in range(0, len(key_list)):\n",
    "    if(DGS_reduced.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "        \n",
    "colors = [color_map.get(node) for node in DGS_reduced.nodes()]\n",
    "plt.figure(figsize=(20,15))\n",
    "nx.draw_networkx(DGS_reduced, node_color = colors, node_size = 500, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"centrality1\"></a></p>\n",
    "## Centrality Analysis #1: \"Celebrities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "#defines a function that returns a sorted list of people (1st element) and the number of connections (2nd element)\n",
    "def sorted_map(map):\n",
    "    sorted_map = sorted(map.items(), key=operator.itemgetter(1), reverse = True) \n",
    "    return(sorted_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a function that returns top n \"celebrities\" in form of data frame\n",
    "\n",
    "def getCeleb(g, n, user_type =None):\n",
    "    d=nx.degree(g) \n",
    "    ds=sorted_map(d)\n",
    "    ds_critic = []\n",
    "    ds_artist = []\n",
    "    \n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(g.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(g.nodes())] \n",
    "    \n",
    "    for i in range(0,len(ds)):\n",
    "        if (ds[i][0] in l_list):\n",
    "            ds_critic.append(ds[i])\n",
    "        else:\n",
    "            ds_artist.append(ds[i])\n",
    "    \n",
    "    if (user_type == 'critic'):\n",
    "        temp = ds_critic\n",
    "    elif (user_type == 'artist'):\n",
    "        temp = ds_artist[0:n]\n",
    "    else:\n",
    "        temp = ds[0:n]\n",
    "    \n",
    "    import heapq\n",
    "    b = [x[1] for x in temp]\n",
    "    b_n = min(heapq.nlargest(n, set(b)))\n",
    "    ans = [x for x in temp if x[1]>=b_n]  \n",
    "    \n",
    "    return(pd.DataFrame(ans, columns = [\"id\", \"num_connections\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "g = get_graph(get_dataframe('follow')) \n",
    "g_reduced = filter_graph(g)\n",
    "n = 5\n",
    "user_type = 'critic'\n",
    "print(\"Top %d %ss by number of connections (%s, #connections):\" %(n,user_type, user_type))\n",
    "getCeleb(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = 'artist'\n",
    "print(\"Top %d %ss by number of connections (%s, #connections):\" %(n,user_type, user_type))\n",
    "getCeleb(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = 'all user'\n",
    "print(\"Top %d %ss by number of connections (%s, #connections):\" %(n,user_type, user_type))\n",
    "getCeleb(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"centrality2\"></a></p>\n",
    "## Centrality Analysis #2: \"Gossipmongers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that returns top n \"gossipmongers\" by critic/artist in form of data frame\n",
    "\n",
    "def getClose(g, n, user_type =None):\n",
    "    c = nx.closeness_centrality(g)\n",
    "    cs=sorted_map(c)\n",
    "    cs_critic = []\n",
    "    cs_artist = []\n",
    "    \n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(g.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(g.nodes())] \n",
    "    \n",
    "    for i in range(0,len(cs)):\n",
    "        if (cs[i][0] in l_list):\n",
    "            cs_critic.append(cs[i])\n",
    "        else:\n",
    "            cs_artist.append(cs[i])\n",
    "    \n",
    "    if (user_type == 'critic'):\n",
    "        ans = cs_critic[0:n]\n",
    "    elif (user_type == 'artist'):\n",
    "        ans = cs_artist[0:n]\n",
    "    else:\n",
    "        ans =cs[0:n]\n",
    "    return(pd.DataFrame(ans, columns = [\"id\", \"closeness\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = 'critic'\n",
    "print(\"Top %d %ss by closeness measure (%s, closeness):\" %(n,user_type, user_type))\n",
    "getClose(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = 'artist'\n",
    "print(\"Top %d %ss by closeness measure (%s, closeness):\" %(n,user_type, user_type))\n",
    "getClose(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = 'all user'\n",
    "print(\"Top %d %ss by closeness measure (%s, closeness):\" %(n,user_type, user_type))\n",
    "getClose(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"centrality3\"></a></p>\n",
    "## Centrality Analysis #3: \"Boundary Spanners\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Function that returns top n \"boundary spanners\" by critic/artist\n",
    "\n",
    "def getSpan(g, n, user_type=None):\n",
    "    b = nx.betweenness_centrality(g)\n",
    "    bs=sorted_map(b)\n",
    "    bs_critic = []\n",
    "    bs_artist = []\n",
    "    \n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(g.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(g.nodes())]\n",
    "    \n",
    "    for i in range(0,len(bs)):\n",
    "        if (bs[i][0] in l_list):\n",
    "            bs_critic.append(bs[i])\n",
    "        else:\n",
    "            bs_artist.append(bs[i])\n",
    "    \n",
    "    if (user_type == 'critic'):\n",
    "        ans = bs_critic[0:n]\n",
    "    elif (user_type == 'artist'):\n",
    "        ans = bs_artist[0:n]\n",
    "    else:\n",
    "        ans = bs[0:n]\n",
    "    return(pd.DataFrame(ans, columns = [\"id\", \"betwenness\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = \"critic\"\n",
    "print(\"Top %d %ss by betweenness measure (%s_id, betweenness):\" %(n,user_type, user_type))\n",
    "getSpan(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = \"artist\"\n",
    "print(\"Top %d %ss by betweenness measure (%s_id, betweenness):\" %(n,user_type, user_type))\n",
    "getSpan(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = \"all user\"\n",
    "print(\"Top %d %ss by betweenness measure (%s_id, betweenness):\" %(n,user_type, user_type))\n",
    "getSpan(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><a name=\"centrality4\"></a></p>\n",
    "## Centrality Analysis #4: \"Gray Cardinals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate eigenvalues\n",
    "e = nx.eigenvector_centrality_numpy(g_reduced)\n",
    "es = sorted_map(e)\n",
    "es\n",
    "\n",
    "#check the eigenvalues are greater than 0 \n",
    "#(https://stackoverflow.com/questions/43208737/using-networkx-to-calculate-eigenvector-centrality)\n",
    "es[-1][1]>0\n",
    "\n",
    "# define function that returns top n people by eigenvalue\n",
    "def getEigen(g, n, user_type =None):\n",
    "    e = nx.eigenvector_centrality_numpy(g)\n",
    "    es = sorted_map(e)\n",
    "    \n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(g.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(g.nodes())]\n",
    "    \n",
    "    if (es[-1][1]>0):\n",
    "        es_critic = []\n",
    "        es_artist = []\n",
    "        \n",
    "        for i in range(0,len(es)):\n",
    "            if (es[i][0] in l_list):\n",
    "                es_critic.append(es[i])\n",
    "            else:\n",
    "                es_artist.append(es[i])\n",
    "                \n",
    "        if (user_type == 'critic'):\n",
    "            ans = es_critic[0:n]\n",
    "        elif (user_type == 'artist'):\n",
    "            ans = es_artist[0:n]\n",
    "        else:\n",
    "            ans =es[0:n]\n",
    "        \n",
    "        return(pd.DataFrame(ans, columns = [\"id\", \"eigenvalue\"]))\n",
    "    else:\n",
    "        return(\"No maximum eigenvalue found.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = 'critic'\n",
    "print(\"Top %d %ss by eigenvalue (%s, eigenvalue):\" %(n,user_type, user_type))\n",
    "getEigen(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = 'artist'\n",
    "print(\"Top %d %ss by eigenvalue (%s, eigenvalue):\" %(n,user_type, user_type))\n",
    "getEigen(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = 'all user'\n",
    "print(\"Top %d %ss by eigenvalue (%s, eigenvalue):\" %(n,user_type, user_type))\n",
    "getEigen(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><a name=\"centrality5\"></a></p>\n",
    "## Centrality Analysis #5: Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that returns top n \"boundary spanners\" by critic/artist\n",
    "\n",
    "def getPgRank(g, n, user_type=None):\n",
    "    p = nx.pagerank(g)\n",
    "    ps=sorted_map(p)\n",
    "    ps_critic = []\n",
    "    ps_artist = []\n",
    "    \n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(g.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(g.nodes())]\n",
    "    \n",
    "    for i in range(0,len(ps)):\n",
    "        if (ps[i][0] in l_list):\n",
    "            ps_critic.append(ps[i])\n",
    "        else:\n",
    "            ps_artist.append(ps[i])\n",
    "    \n",
    "    if (user_type == 'critic'):\n",
    "        ans = ps_critic[0:n]\n",
    "    elif (user_type == 'artist'):\n",
    "        ans = ps_artist[0:n]\n",
    "    else:\n",
    "        ans = ps[0:n]\n",
    "    return(pd.DataFrame(ans, columns = [\"id\", \"page_rank\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = \"critic\"\n",
    "print(\"Top %d %ss by PageRank (%s, page_rank):\" %(n,user_type, user_type))\n",
    "getPgRank(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = \"artist\"\n",
    "print(\"Top %d %ss by PageRank (%s, page_rank):\" %(n,user_type, user_type))\n",
    "getPgRank(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test function\n",
    "n = 5\n",
    "user_type = \"all user\"\n",
    "print(\"Top %d %ss by PageRank (%s, page_rank):\" %(n,user_type, user_type))\n",
    "getPgRank(g_reduced, n, user_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"centrality_summary\"></a></p>\n",
    "## Centrality Analysis: Summary\n",
    "\n",
    "-- Define function that returns top users for all centrality measures\n",
    "\n",
    "-- Define function that returns centrality measures for specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function that returns top n for each of the previous centrality measures in a data frame and sorts by\n",
    "#number of connections\n",
    "def topCentral(g, n, user_type):\n",
    "    df_celeb = getCeleb(g, n, user_type)\n",
    "    df_close = getClose(g, n, user_type)\n",
    "    df_span = getSpan(g, n, user_type)\n",
    "    df_eigen = getEigen(g, n, user_type)\n",
    "    df_rank = getPgRank(g, n, user_type)\n",
    "    \n",
    "    names1 = df_celeb['id']\n",
    "    names2 = df_close['id']\n",
    "    names3 = df_span['id']\n",
    "    \n",
    "    if(type(df_eigen) == pd.DataFrame):\n",
    "        names4 = df_eigen['id']\n",
    "    else:\n",
    "        names4 = names1\n",
    "    names5 = df_rank['id']\n",
    "    names=list(set(names1) | set(names2) | set (names3) | set (names4) | set (names5))\n",
    "    \n",
    "    df_celeb2 = getCeleb(g, len(g), user_type)\n",
    "    df_close2 = getClose(g, len(g), user_type)\n",
    "    df_span2 = getSpan(g, len(g), user_type)\n",
    "    df_eigen2 = getEigen(g, len(g), user_type)\n",
    "    df_rank2 = getPgRank(g, len(g), user_type)\n",
    "    \n",
    "    if(type(df_eigen) == pd.DataFrame):    \n",
    "        table = [[name,df_celeb2.iloc[df_celeb2[df_celeb2['id']==name].index.values.astype(int)[0],1], \\\n",
    "            df_close2.iloc[df_close2[df_close2['id']==name].index.values.astype(int)[0],1], \\\n",
    "            df_span2.iloc[df_span2[df_span2['id']==name].index.values.astype(int)[0],1], \\\n",
    "            df_eigen2.iloc[df_eigen2[df_eigen2['id']==name].index.values.astype(int)[0],1],\\\n",
    "            df_rank2.iloc[df_rank2[df_rank2['id']==name].index.values.astype(int)[0],1]] for name in names] \n",
    "    \n",
    "    else:\n",
    "        table = [[name,df_celeb2.iloc[df_celeb2[df_celeb2['id']==name].index.values.astype(int)[0],1], \\\n",
    "            df_close2.iloc[df_close2[df_close2['id']==name].index.values.astype(int)[0],1], \\\n",
    "            df_span2.iloc[df_span2[df_span2['id']==name].index.values.astype(int)[0],1], \\\n",
    "            np.nan, df_rank2.iloc[df_rank2[df_rank2['id']==name].index.values.astype(int)[0],1]]\n",
    "            for name in names] \n",
    "    df = pd.DataFrame(table[1:],columns= ['id',df_celeb.columns.get_values()[1], \n",
    "                      df_close.columns.get_values()[1], df_span.columns.get_values()[1],\n",
    "                      \"eigenvalue\", df_rank.columns.get_values()[1]])\n",
    "    \n",
    "    df = df.sort_values(df_celeb.columns.get_values()[1], ascending = False)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test getCentral function by iterating it through the various connection types\n",
    "\n",
    "#Arguments passed to function\n",
    "n = 3\n",
    "user_type = 'critic'\n",
    "connection = ['follow', 'message', 'view', 'sociallink']\n",
    "\n",
    "for i in connection:\n",
    "    df = get_dataframe(i)\n",
    "    g = get_graph(df)\n",
    "    g_reduced = filter_graph(g)\n",
    "    print(i, \" connection type\", '\\n')\n",
    "    print(\"Summary of top %ss by various centrality measures, sorted by number of connections:\" %( user_type),'\\n')\n",
    "    print(topCentral(g_reduced, n, user_type), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function that returns 1) data frame with the various centrality measures for a given user \n",
    "# and 2) second data frame with ranks \n",
    "\n",
    "def getCentral (user):\n",
    "    connection = ['follow', 'message', 'view', 'sociallink']\n",
    "    table1 =[] #table for centrality measures\n",
    "    table2 =[] #table for centrality ranks\n",
    "    \n",
    "    for i in connection:\n",
    "        temp_df = get_dataframe(i)\n",
    "        g = get_graph(temp_df)\n",
    "        g = filter_graph(g)\n",
    "        \n",
    "        #code for data frame with centrality measures\n",
    "        d = nx.degree(g)[user]\n",
    "        c = nx.closeness_centrality(g)[user]\n",
    "        b = nx.betweenness_centrality(g)[user]\n",
    "        p = nx.pagerank(g)[user]\n",
    "        \n",
    "        e = nx.eigenvector_centrality_numpy(g)\n",
    "        es = sorted_map(e)\n",
    "        \n",
    "        if (es[-1][1]>0):\n",
    "            e = nx.eigenvector_centrality_numpy(g)[user]\n",
    "        else:\n",
    "            e =np.nan\n",
    "        \n",
    "        table1.append([i,d, c, b, e, p])\n",
    "        \n",
    "        #code for data frame with centrality ranks\n",
    "        max_ = len(g.nodes())\n",
    "        df = getCeleb(g, max_)\n",
    "        d_rank = df[df['id'] == user].index.values[0]+1\n",
    "        df = getClose(g, max_)\n",
    "        c_rank = df[df['id'] == user].index.values[0]+1\n",
    "        df = getSpan(g, max_)\n",
    "        b_rank = df[df['id'] == user].index.values[0]+1\n",
    "        df = getPgRank(g, max_)\n",
    "        p_rank = df[df['id'] == user].index.values[0]+1\n",
    "        \n",
    "        df = getEigen(g, max_)\n",
    "        if (type(df) == pd.DataFrame):\n",
    "            e_rank = df[df['id'] == user].index.values[0]+1\n",
    "        else:\n",
    "            e_rank =np.nan\n",
    "            \n",
    "        table2.append([i,d_rank, c_rank, b_rank, e_rank, p_rank])\n",
    "     \n",
    "    df1 = pd.DataFrame(table1, columns = ['connection_type', 'num_connections', 'closeness', 'betweenness', \n",
    "                                        'eigenvalue',  'page_rank'])\n",
    "        \n",
    "    df1.set_index('connection_type')\n",
    "    \n",
    "    df2 = pd.DataFrame(table2, columns = ['connection_type', 'num_connections', 'closeness', 'betweenness', \n",
    "                                        'eigenvalue',  'page_rank'])\n",
    "        \n",
    "    df2.set_index('connection_type')\n",
    "    \n",
    "        \n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test getCentral function\n",
    "getCentral(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><a name=\"ccc\"></a></p>\n",
    "## Components and Subgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subcomponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define function that returns the top n components (graphs objects) by number of nodes\n",
    "## this can possibly be fed into a pipeline for further analysis of the components\n",
    "def getComponent(g, n):\n",
    "    graphs = sorted(nx.connected_component_subgraphs(g), key = len, reverse=True)\n",
    "    n_nodes = [nx.number_of_nodes(g) for g in graphs]\n",
    "    \n",
    "    if (n>len(graphs)):\n",
    "        return(\"Number entered exceeds max value of %d. Please try again\" %(len(graphs)))\n",
    "    else:\n",
    "        import heapq\n",
    "        min_= min(heapq.nlargest(n, set(n_nodes)))        \n",
    "        ans = [g for g in graphs if nx.number_of_nodes(g) >=min_]\n",
    "        return(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Test function\n",
    "e=nx.read_pajek(\"egypt_retweets.net\")\n",
    "graphs = sorted(nx.connected_component_subgraphs(e),key = len, reverse=True)\n",
    "n_nodes = [nx.number_of_nodes(g) for g in graphs]\n",
    "getComponent(e, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Islands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function that removes edges with weights below a certain level and returns\n",
    "def trim_edges(g, weight=1): \n",
    "    g2=nx.Graph()\n",
    "    for f, to, edata in g.edges(data=True): \n",
    "        if (edata['weight']) > weight:\n",
    "            g2.add_edge(f,to,edata)\n",
    "        return g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a function to gradually trim the network into smaller networks. Returns threshold value and graph object.\n",
    "#This can possibly be fed into a pipeline for further analysis of the islands.\n",
    "def island_method(g, iterations=5):\n",
    "    weights= [edata['weight'] for f,to,edata in g.edges(data=True)]\n",
    "    mn=int(min(weights))\n",
    "    mx=int(max(weights))\n",
    "    step=int((mx-mn)/iterations)\n",
    "    \n",
    "    return [[threshold, trim_edges(g, threshold)] for threshold in range(mn,mx,step)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test island_method function on biggest component\n",
    "cc=getComponent(e,5)[0]\n",
    "islands=island_method(cc)\n",
    "islands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ego graphs and networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function that returns ego graph object for given user, connection type, depth of search\n",
    "\n",
    "def getEgo (user, connection, depth):\n",
    "    df = get_dataframe(connection)\n",
    "    g = get_graph(df)\n",
    "    g = filter_graph(g)\n",
    "    ego = nx.Graph(nx.ego_graph(g,user, radius=depth))\n",
    "    return ego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test getEgo function\n",
    "#Draw ego graph\n",
    "\n",
    "user = getEgo(27, 'follow', 1)\n",
    "\n",
    "color_map = {}\n",
    "key_list = user.nodes()\n",
    "\n",
    "for i in range(0, len(key_list)):\n",
    "    if(user.node[key_list[i]]['user_type'] == 'critic'):\n",
    "        color_map[key_list[i]] = 'b'\n",
    "    else:\n",
    "        color_map[key_list[i]] = 'r'\n",
    "\n",
    "        \n",
    "colors = [color_map.get(node) for node in user.nodes()]\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "nx.draw_networkx(user, node_color = colors, node_size = 500, alpha = 0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function to get df for each user that shows number of connections and portion of connections that are\n",
    "#connected to each other\n",
    "def ego_graph_df(connection, user, degree=1):\n",
    "    \n",
    "    ego_graph = getEgo(user, connection, degree)\n",
    "    num = len(ego_graph)\n",
    "    avg = round(nx.average_clustering(ego_graph),2)\n",
    "    ans = [[num, avg]]\n",
    "    return (pd.DataFrame(ans, columns = [\"num_connections\", \"percent_connected\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ego_graph_df('follow',27,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#9/11 example from Book. Columns in the \"edgelist.text\" file, in order, are: \n",
    "#1)from, 2) to, 3) strength of tie, 4) level to which tie has been confirmed\n",
    "#\"attrib.txt\" file contains the flight each person was on.\n",
    "\n",
    "import csv \n",
    "\n",
    "with open('9_11_edgelist.txt', 'r') as f:\n",
    "    reader = csv.reader(f) \n",
    "    g = nx.Graph()\n",
    "    for row in reader:\n",
    "        g.add_edge(row[0],row[1],weight=row[2],conf=row[3])\n",
    "    \n",
    "    for n in g.nodes_iter(): \n",
    "        g.node[n]['flight']='None'\n",
    "\n",
    "with open('9_11_attrib.txt', 'r') as f:\n",
    "    attribute = csv.reader(f) \n",
    "    for row in attribute:\n",
    "        g.node[row[0]]['flight']=row[1]\n",
    "\n",
    "##Examine largest subcomponent\n",
    "components=sorted(nx.connected_component_subgraphs(g), key = len, reverse=True)\n",
    "cc = components[0]\n",
    "\n",
    "#Plot largest subcomponent. The function reads node attributes and assigns colors to \n",
    "#them based on attribute values. \"multimode\" function is defined in multimode.py file.\n",
    "\n",
    "from collections import defaultdict\n",
    "import multimode as mm\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "mm.plot_multimode(cc,type_string='flight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Census of triad types using sample data. First number is number of bidirectional edges. \n",
    "#Second number is number of single edges. Third number is number of non-existent edges.\n",
    "import triadic\n",
    "import draw_triads\n",
    "g=nx.DiGraph(nx.krackhardt_kite_graph())\n",
    "\n",
    "census, node_census = triadic.triadic_census(g) \n",
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate table of nodes with number of instances in each of the triad types\n",
    "\n",
    "keys=node_census[0].keys()\n",
    "## Generate a table header\n",
    "print ('| Node |', ' | '.join(keys))\n",
    "## Generate table contents\n",
    "## A little magic is required to convert ints to strings \n",
    "for k in node_census.keys():\n",
    "    print ('|', k, '|',' | '.join([str(v) for v in node_census[k].values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#See which users are in the most closed triads, i.e., cliques. First column is user, second is triads.\n",
    "#Define function that returns count of closed triads each user is in by type of connection (follow, message)\n",
    "\n",
    "\n",
    "def getCensus(connection, n, user_type = None):\n",
    "    df = get_dataframe(i)\n",
    "    g = get_graph(df)\n",
    "    g = filter_graph(g)\n",
    "    \n",
    "    listeners, artists = bh.users()\n",
    "    l = listeners['id'].tolist()\n",
    "    a = artists['id'].tolist()\n",
    "    l_list = [x for x in l if x in set(g.nodes())] #list of critics \n",
    "    a_list = [x for x in a if x in set(g.nodes())]\n",
    "        \n",
    "    census, node_census = triadic.triadic_census(g)\n",
    "    \n",
    "    if user_type =='critic':\n",
    "        user_list = list(set(node_census.keys()) & set(l_list))\n",
    "    elif user_type == 'artist':\n",
    "        user_list = list(set(node_census.keys()) & set(a_list))\n",
    "    else:\n",
    "        user_list = node_census.keys()\n",
    "    closed_triads=[[v,-k] for k,v in sorted([[-node_census[k]['300'],k] for k in user_list])]\n",
    "    closed_triads_df = pd.DataFrame(closed_triads, columns = ['id', 'closed_triads'])\n",
    "    return(closed_triads_df[0:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test code\n",
    "getCensus('follow', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hc\n",
    "\n",
    "eco=nx.read_pajek(\"economic.net\")\n",
    "hc.create_hc(eco, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2-Mode Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get dataframes for all four 2-mode networks\n",
    "df_rating = get_dataframe('rating')\n",
    "df_save = get_dataframe('save')\n",
    "df_spotlight = get_dataframe('spotlight')\n",
    "df_comment = get_dataframe('comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# negate value of music_id column to make 2 non-intersecting sets \n",
    "# of node values: user_id, music_id\n",
    "negate_musicid_1(df_rating)\n",
    "negate_musicid_2(df_save)\n",
    "negate_musicid_2(df_spotlight)\n",
    "negate_musicid_1(df_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get bipartite graphs of each 2-mode connection type\n",
    "BG_rating = get_bigraph_1(df_rating)\n",
    "BG_save = get_bigraph_2(df_save)\n",
    "BG_spotlight = get_bigraph_2(df_spotlight)\n",
    "BG_comment = get_bigraph_1(df_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get lists for top and bottom nodes for each bipartite graph\n",
    "rating_top, rating_bottom = get_bipartite_nodes(BG_rating)\n",
    "save_top, save_bottom = get_bipartite_nodes(BG_save)\n",
    "spotlight_top, spotlight_bottom = get_bipartite_nodes(BG_spotlight)\n",
    "comment_top, comment_bottom = get_bipartite_nodes(BG_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get positional info for how to plot nodes of bipartite graph\n",
    "rating_pos = get_pos_1(df_rating)\n",
    "save_pos = get_pos_2(df_save)\n",
    "spotlight_pos = get_pos_2(df_spotlight)\n",
    "comment_pos = get_pos_1(df_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(BG_rating, rating_pos, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(BG_save, save_pos, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(BG_spotlight, spotlight_pos, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(BG_comment, comment_pos, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WPG_rating_user = bipartite.weighted_projected_graph(BG_rating, rating_top)\n",
    "WPG_rating_music = bipartite.weighted_projected_graph(BG_rating, rating_bottom)\n",
    "WPG_save_user = bipartite.weighted_projected_graph(BG_rating, save_top)\n",
    "WPG_save_music = bipartite.weighted_projected_graph(BG_rating, save_bottom)\n",
    "WPG_spotlight_user = bipartite.weighted_projected_graph(BG_rating, spotlight_top)\n",
    "WPG_spotlight_music = bipartite.weighted_projected_graph(BG_rating, spotlight_bottom)\n",
    "WPG_comment_user = bipartite.weighted_projected_graph(BG_rating, comment_top)\n",
    "WPG_comment_music = bipartite.weighted_projected_graph(BG_rating, comment_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(WPG_rating_user, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(WPG_rating_music, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(WPG_save_user, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(WPG_save_music, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(WPG_spotlight_user, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(WPG_spotlight_music, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(WPG_comment_user, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(WPG_comment_music, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userlist_rating = get_userlists(df_rating)\n",
    "musiclist_rating = get_musiclists1(df_rating)\n",
    "userlist_comments = get_userlists(df_comments)\n",
    "musiclist_comments = get_musiclists1(df_comments)\n",
    "userlist_spotlighted = get_userlists(df_spotlighted)\n",
    "musiclist_spotlighted = get_musiclists2(df_spotlighted)\n",
    "userlist_saved = get_userlists(df_saved)\n",
    "musiclist_saved = get_musiclists2(df_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_rating_net = bi.weighted_projected_graph(GR, musiclist_rating, ratio = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.is_connected(BG_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.is_bipartite(BG_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bottom_nodes, top_nodes = bipartite.sets(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom_nodes, top_nodes = bipartite.sets(B)\n",
    "top_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==0}\n",
    "bottom_nodes = set(B) - top_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G=bipartite.projected_graph(B, top_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bipartite.color(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = {node:[0, i] for i,node in enumerate(df_rating['user_id'])}\n",
    "pos.update({node:[1, i] for i,node in enumerate(df_rating['user_music_id'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(enumerate(df_rating['user_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,50))\n",
    "nx.draw_networkx(B, pos, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "nx.draw_networkx(B, node_size = 500, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
